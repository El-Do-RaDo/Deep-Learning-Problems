# Sementic Segmentation
## FCN
### 网络结构

与经典的CNN在卷积层之后使用全连接层得到固定长度的特征向量进行分类（全联接层＋softmax输出）不同，FCN可以接受任意尺寸的输入图像，采用反卷积层对最后一个卷积层的feature map进行上采样, 使它恢复到输入图像相同的尺寸，从而可以对每个像素都产生了一个预测, 同时保留了原始输入图像中的空间信息, 最后在上采样的特征图上进行逐像素分类。

### 全卷积网络

* CNN特点
    - 较浅的卷积层感知域较小，学习到一些局部区域的特征
    - 较深的卷积层具有较大的感知域，能够学习到更加抽象一些的特征
    - 高层的抽象特征对物体的大小、位置和方向等敏感性更低，从而有助于识别性能的提高, 所以我们常常可以将卷积层看作是特征提取器
* CNN像素分类很难
    - 存储开销很大：例如对每个像素使用的图像块的大小为15x15，然后不断滑动窗口，每次滑动的窗口给CNN进行判别分类，因此则所需的存储空间根据滑动窗口的次数和大小急剧上升。
    - 计算效率低下：相邻的像素块基本上是重复的，针对每个像素块逐个计算卷积，这种计算也有很大程度上的重复。
    - 像素块大小的限制了感知区域的大小：通常像素块的大小比整幅图像的大小小很多，只能提取一些局部的特征，从而导致分类的性能受到限制。
* 全连接层与全卷积层
    - 对于任一个卷积层，都存在一个能实现和它一样的前向传播函数的全连接层
    - 任何全连接层都可以被转化为卷积层
* FCN输入图像大小任意
    - 对于CNN，一幅输入图片在经过卷积和pooling层时，这些层是不关心图片大小的。对于一个inputsize大小的输入feature map，滑窗卷积，输出outputsize大小的feature map即可。pooling层同理。
    - 但是在进入全连接层时，feature map（假设大小为n×n）要拉成一条向量，而向量中每个元素（共n×n个）作为一个结点都要与下一个层的所有结点（假设4096个）全连接，这里的权值个数是4096×n×n，而我们知道神经网络结构一旦确定，它的权值个数都是固定的，所以这个n不能变化，n是conv5的outputsize，所以层层向回看，每个outputsize都要固定，那每个inputsize都要固定，因此输入图片大小要固定。
* 把全连接层的权重W重塑成卷积层的滤波器有什么好处
    - 在单个向前传播的过程中, 使得卷积网络在一张更大的输入图片上滑动，从而得到多个输出(可以理解为一个label map)

### 反卷积层

* Upsampling的操作可以看成是反卷积(deconvolutional)，卷积运算的参数和CNN的参数一样是在训练FCN模型的过程中通过bp算法学习得到。反卷积层也是卷积层，不关心input大小，滑窗卷积后输出output。deconv并不是真正的deconvolution（卷积的逆变换），最近比较公认的叫法应该是transposed convolution，deconv的前向传播就是conv的反向传播。
* 反卷积参数: 利用卷积过程filter的转置（实际上就是水平和竖直方向上翻转filter）作为计算卷积前的特征图
* 反卷积学习率为0
* 怎么使反卷积的output大小和输入图片大小一致，从而得到pixel level prediction
    - FCN里面全部都是卷积层（pooling也看成卷积），卷积层不关心input的大小，inputsize和outputsize之间存在线性关系。
    - 假设图片输入为[n×n]大小，第一个卷积层输出map就为`conv1_out=(n−kernel)/stride+1`, 记做`conv1_out=f(n)`, 依次类推，`conv5_out=f(conv5_in.size)=f(…f(n))`, 反卷积是要使`n=f′(conv5_out)`成立，要确定`f′`，就需要设置deconvolution层的kernel_size，stride，padding，计算如下：
        ```shell
        layer
        {
            name: "upsample", type: "Deconvolution"
            bottom: "{{bottom_name}}" top: "{{top_name}}"
            convolution_param
            {
                kernel_size: {{2 * factor - factor % 2}}
                stride: {{factor}}
                num_output: {{C}}
                group: {{C}}
                pad: {{ceil((factor - 1) / 2.)}}
                weight_filler: { type: "bilinear" }
                bias_term: false
            }
            param { lr_mult: 0 decay_mult: 0 }
        }
        ```
        factor是指反卷积之前的所有卷积pooling层的累积采样步长，卷积层使feature map变小，是因为stride，卷积操作造成的影响一般通过padding来消除，因此，累积采样步长factor就等于反卷积之前所有层的stride的乘积。

### 跳级结构

* 对CNN的结果做处理，得到了dense prediction，而作者在试验中发现，得到的分割结果比较粗糙，所以考虑加入更多前层的细节信息，也就是把倒数第几层的输出和最后的输出做一个fusion
* 实验表明，这样的分割结果更细致更准确。在逐层fusion的过程中，做到第三行再往下，结果又会变差。具体原因，根据卷积网络的特点，低层网络的信息更接近原图，包含更多噪声；而高层网络的的信息更抽象，包含更多抽象特征。因此，低层的fusion可能导致效果变差。

### 模型训练

* 用AlexNet，VGG16或者GoogleNet训练好的模型做初始化，在这个基础上做fine-tuning，全部都fine-tuning，只需在末尾加上upsampling，参数的学习还是利用CNN本身的反向传播原理
* 采用whole image做训练，不进行patchwise sampling。实验证明直接用全图已经很effective and efficient。项目中之所以进行patchwise sampling，是因为数据量不足，并且原图过大导致显存不足。
* 对class score的卷积层做全零初始化。随机初始化在性能和收敛上没有优势

### 评价

#### 网络逻辑
* 想要精确预测每个像素的分割结果，必须经历从大到小，再从小到大的两个过程
* 在升采样过程中，分阶段增大比一步到位效果更好
* 在升采样的每个阶段，使用降采样对应层的特征进行辅助

#### 缺点
* 得到的结果还是不够精细。进行8倍上采样虽然比32倍的效果好了很多，但是上采样的结果还是比较模糊和平滑，对图像中的细节不敏感
* 对各个像素进行分类，没有充分考虑像素与像素之间的关系。忽略了在通常的基于像素分类的分割方法中使用的空间规整（spatial regularization）步骤，缺乏空间一致性

### Reference

* http://simtalk.cn/2016/11/01/Fully-Convolutional-Networks/
* https://arxiv.org/abs/1411.4038
* http://www.jianshu.com/p/91c5db272725

## U-Net

### 概述
* 一种编码器-解码器结构。编码器逐渐减少池化层的空间维度，解码器逐步修复物体的细节和空间维度。编码器和解码器之间通常存在快捷连接，因此能帮助解码器更好地修复目标的细节。

### 网络架构

* 卷积层的数量大约在20个左右，4次下采样，4次上采样。输入图像大于输出图像，因为在本论文中对输入图像做了镜像操作。
* 这个网络没有全连接,只有卷积和下采样. 这也是一个端到端的图像, 即输入是一幅图像, 输出也是一副图像.

## DeepLab

### 三大挑战

* 特征分辨率减少：是由重复最大池化和降采样（步长跨度）造成的，它们作用于用来做图像分类的深度卷积神经网络的一系列层上。深度卷积神经网络采用全卷积方式的时候，会明显降低特征地图的空间分辨率。为了解决这个问题，有效地生成更稠密的特征地图，我们从深度卷积神经网络中最后的最大池化层中拿掉降采样操作，将上采样滤波器加入接下来的卷积层中，在更高的采样率上计算特征地图。滤波上采样就是在非零滤波器之间插入空洞。在实践中，可以用多孔卷积恢复全分辨率的特征地图，计算更稠密的特征地图，接着在原图像大小和特征响应之间做一个简单的双线性插值。这种算法提供了简单但强有力的方法在稠密预测任务中使用反卷积层。与通常的大滤波器卷积相比，多孔卷积可以有效地增加滤波器的视野而不会增加参数数量或计算量。
* 不同尺度下的物体的存在状况：是物体在多尺度图像中的状态造成的。一个处理这个问题的标准方法是给深度神经网络提供这个图像的重新缩放的版本，再合成特征或计算地图分值。我们发现这个方法确实可以增加系统的性能，但是需要在所有深度卷积神经网络的层上对输入图像的多尺度版本计算特征响应。受到空间金字塔池化的激发，采用计算效率更好的算法，在多个采样率上重采样特定的特征层来做卷积。这需要用互补有效视野的多个滤波器来探测原图像，因此可以在多个尺度上有用的图像中捕捉物体。与真正对特征重采样不同，我们用不同采样率的多个并行的多孔卷积层做这种映射；我们称这种技术为“多孔空间金字塔池化（ASPP）”。
* 由于深度卷积神经网络的不变性造成的定位精度减少：是物体分类器要求对空间变换具有不变性，内在地限制了深度卷积神经网络的空间精度。减轻这个问题的一个方法是在计算最终的分割结果时，跳层从多个网络层中提取“超列”特征。需要提出的是，我们采用全连接条件随机场CRF，提升了模型的能力可以抓取精细的细节。使用全连接配对条件随机场，计算效率更高，可以抓取精细的边缘细节，也适用于较长的依赖项。当它与深度卷积神经网络的像素级别分类器耦合的时候，可以取得更好的结果。

### 网络结构

* 一个深度卷积神经网络（VGG-16，或ResNet-101）训练用于图像分类任务
* 将所有全连接层改为卷积层
* 通过多孔卷积增加特征分辨率，就可以计算每8个像素的特征响应而不是原始网络中的每32个像素
* 使用双线性内插值，用因子8上采样分值地图，以达到原始图像的分辨率，得到从输入到一个全连接的条件随机场，用于优化分割结果

### 优点

* 速度：由于多孔卷积的优点，稠密深度卷积神经网络在nVidia Titan X GPU上的运行速度是8FPS，全连接条件随机场的平均场推导在CPU上需要0.5秒
* 精度：在几个数据集中获得了最好的结果
* 简洁：系统串联了两个构建好的模块，深度卷积神经网络和条件随机场

### 方法

* 用于稠密特征提取和视野增大的多孔卷积：在多孔算法中提高非抽取小波变换的计算效率。
    - 在深度卷积神经网络中可以使用层链中的多孔卷积，可以在任意高的分辨率上计算最后的深度卷积神经网络响应。
    - 多孔卷积可以在任何深度卷积神经网络层上任意扩大滤波器的视野。
    - 插入空洞（零元素）或者对输入特征地图同等稀疏地采样，来对滤波器进行上采样。
    - 用一个与多孔卷积比例r相同的因子对输入特征地图进行子采样，对每个r×r可能的偏移，消除隔行扫描生成一个r2降低的分辨率地图。接下来对这些中间地图使用标准卷积，隔行扫描生成原始图像分辨率。将多孔卷积转换成常规卷积，这样我们就可以使用现有优化好的卷积例程。
* 用多孔空间金字塔池化的多尺度图像表示
    - 标准多尺度处理：用共享相同参数的并行深度卷积神经网络分支，从多个原始图像不同尺度版本，提取深度卷积神经网络得分地图。为了生成最后的结果，我们从并行的深度卷积神经网络分支到原始图像分辨率之间对特征地图进行双线性插值，并且融合它们，在不同尺度上获得每个位置的最大响应。在训练和测试时都这样做。多尺度处理明显增强了性能，但是需要对输入图像的多个尺度上在所有深度卷积神经网络层上计算特征响应。
    - 空间金字塔池化方法：任意一个尺度上的区域都可以用在这个单一尺度上重采样卷积特征进行精确有效地分类。我们实现了他们方法的一种变化形式，使用多个不同采样率上的多个并行多孔卷积层。每个采样率上提取的特征再用单独的分支处理，融合生成最后的结果。
* 用于精确边界恢复的全连接条件随机场的结构预测
    - 我们将深度卷积神经网络的识别能力和全连接条件随机场优化的定位精度耦合在一起，非常成功地处理定位挑战问题，生成了精确的语义分割结果，在一个详细的层级上恢复物体边界，超越了现有方法

### Reference

* http://blog.csdn.net/cicibabe/article/details/71173965

# Instance segmentation

## Mask R-CNN

### 介绍

* 对于Faster R-CNN来说，对于每个目标对象，它有两个输出，一个是类标签（classlabel），一个是边界框的抵消值（bounding-box offset）
* 在此基础上，Mask R-CNN方法增加了第三个分支的输出：目标掩码。目标掩码与已有的class和box输出的不同在于它需要对目标的空间布局有一个更精细的提取

### 工作机理

* 第一阶段叫做RPN（Region Proposal Network），此步骤提出了候选对象边界框
* 第二阶段本质上就是Fast R-CNN，它使用来自候选框架中的RoIPool来提取特征并进行分类和边界框回归，但Mask R-CNN更进一步的是为每个RoI生成了一个二元掩码
* Mask Representation: 对于每个 RoI 我们使用 一个 FCN 网络来预测 m\*m mask。m\*m是一个小的特征图尺寸，如何将这个小的特征图很好的映射到原始图像上？为此我们提出了一个 叫 RoIAlign 的网络层来解决该问题，它在 mask 预测中扮演了重要的角色
* RoIAlign: RoIPool 是一个标准的提特征运算，它从每个 RoI 提取出一个小的特征（7\*7），RoIPool 首先对浮点的 RoI 进行量化，然后再提取分块直方图，最后通过 maxpool 组合起来。这种分块直方图对于分类没有什么大的影响，但是对像素级别精度的 mask 有很大影响
* 提出了一个 RoIAlign 网络层解决 RoIPool 量化引入的问题，将提取的特征和输入合适的对应起来。避免对 RoI 的边界或 bins 进行量化。使用线性差值精确计算每个 RoI bin 最后组合起来。
